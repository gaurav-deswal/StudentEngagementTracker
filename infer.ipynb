{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n",
      "{'train': 5482, 'test': 1720}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/287 [00:00<?, ?it/s]c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "100%|██████████| 287/287 [04:03<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 1/25 Loss: 1.494581714385124 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0  17   6]\n",
      " [  0   6  94  60]\n",
      " [  0  22 454 436]\n",
      " [  0  15 212 398]]\n",
      "\n",
      "accuracy\t0.49883720930232556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from ResTCN import ResTCN\n",
    "from utils import get_dataloader\n",
    "\n",
    "os.chdir(r\"F:\\RESTCN_CODE\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_epochs = 25\n",
    "batch_size = 6\n",
    "lr = .001\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "\n",
    "# dataloader = get_dataloader(batch_size,\n",
    "#                             'train.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_train'),\n",
    "#                             'test.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_test'))\n",
    "dataloader = get_dataloader(batch_size,\n",
    "                            'csv\\\\train.csv',\n",
    "                            os.getcwd(),\n",
    "                            'csv\\\\validation.csv',\n",
    "                            os.getcwd())\n",
    "\n",
    "dataset_sizes = {x: len(dataloader[x].dataset) for x in ['train','test']}\n",
    "print(dataset_sizes, flush=True) # OUTPUT: {'train': 5482, 'test': 1784}\n",
    "\n",
    "\n",
    "model = ResTCN().to(device)\n",
    "model.load_state_dict(torch.load(r\"resTCN_model.pth\"))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "running_loss=0\n",
    "for phase in ['test']:\n",
    "        model.eval()\n",
    "        running_loss = .0\n",
    "        y_trues = np.empty([0])\n",
    "        y_preds = np.empty([0])\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().squeeze().to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            try:\n",
    "                preds = torch.max(softmax(outputs), dim=1)[1]  # Fix here\n",
    "                # print('HI')\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                continue\n",
    "            \n",
    "\n",
    "            y_trues = np.append(y_trues, labels.data.cpu().numpy())\n",
    "            y_preds = np.append(y_preds, preds.cpu())\n",
    "            \n",
    "            \n",
    "        # if phase == 'train':\n",
    "        #     scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        val_losses.append(epoch_loss)\n",
    "\n",
    "        print(\"[{}] Epoch: {}/{} Loss: {} LR: {}\".format(\n",
    "            phase, 0 + 1, num_epochs, epoch_loss, scheduler.get_last_lr()), flush=True)\n",
    "        print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))\n",
    "        print('\\naccuracy\\t' + str(accuracy_score(y_trues, y_preds)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n",
      "{'train': 5482, 'test': 1720}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/287 [00:00<?, ?it/s]c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "100%|██████████| 287/287 [03:56<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 1/25 Loss: 1.2584605281782704 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  1   1  12   9]\n",
      " [  2   6  83  69]\n",
      " [  5  45 391 471]\n",
      " [  6  40 216 363]]\n",
      "\n",
      "accuracy\t0.4424418604651163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from ResTCN import ResTCN\n",
    "from utils import get_dataloader\n",
    "\n",
    "os.chdir(r\"F:\\RESTCN_CODE\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_epochs = 25\n",
    "batch_size = 6\n",
    "lr = .001\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "\n",
    "# dataloader = get_dataloader(batch_size,\n",
    "#                             'train.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_train'),\n",
    "#                             'test.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_test'))\n",
    "dataloader = get_dataloader(batch_size,\n",
    "                            'csv\\\\train.csv',\n",
    "                            os.getcwd(),\n",
    "                            'csv\\\\validation.csv',\n",
    "                            os.getcwd())\n",
    "\n",
    "dataset_sizes = {x: len(dataloader[x].dataset) for x in ['train','test']}\n",
    "print(dataset_sizes, flush=True) # OUTPUT: {'train': 5482, 'test': 1784}\n",
    "\n",
    "\n",
    "model = ResTCN().to(device)\n",
    "model.load_state_dict(torch.load(r\"resTCN_model_weighted.pth\"))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "running_loss=0\n",
    "for phase in ['test']:\n",
    "        model.eval()\n",
    "        running_loss = .0\n",
    "        y_trues = np.empty([0])\n",
    "        y_preds = np.empty([0])\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().squeeze().to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            try:\n",
    "                preds = torch.max(softmax(outputs), dim=1)[1]  # Fix here\n",
    "                # print('HI')\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                continue\n",
    "            \n",
    "\n",
    "            y_trues = np.append(y_trues, labels.data.cpu().numpy())\n",
    "            y_preds = np.append(y_preds, preds.cpu())\n",
    "            \n",
    "            \n",
    "        # if phase == 'train':\n",
    "        #     scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        val_losses.append(epoch_loss)\n",
    "\n",
    "        print(\"[{}] Epoch: {}/{} Loss: {} LR: {}\".format(\n",
    "            phase, 0 + 1, num_epochs, epoch_loss, scheduler.get_last_lr()), flush=True)\n",
    "        print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))\n",
    "        print('\\naccuracy\\t' + str(accuracy_score(y_trues, y_preds)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n",
      "{'train': 5482, 'test': 1720}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/287 [00:00<?, ?it/s]c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "100%|██████████| 287/287 [03:28<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 1/25 Loss: nan LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[ 23   0   0   0]\n",
      " [160   0   0   0]\n",
      " [912   0   0   0]\n",
      " [625   0   0   0]]\n",
      "\n",
      "accuracy\t0.013372093023255814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from ResTCN import ResTCN\n",
    "from utils import get_dataloader\n",
    "\n",
    "os.chdir(r\"F:\\RESTCN_CODE\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_epochs = 25\n",
    "batch_size = 6\n",
    "lr = .001\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "\n",
    "# dataloader = get_dataloader(batch_size,\n",
    "#                             'train.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_train'),\n",
    "#                             'test.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_test'))\n",
    "dataloader = get_dataloader(batch_size,\n",
    "                            'csv\\\\train.csv',\n",
    "                            os.getcwd(),\n",
    "                            'csv\\\\validation.csv',\n",
    "                            os.getcwd())\n",
    "\n",
    "dataset_sizes = {x: len(dataloader[x].dataset) for x in ['train','test']}\n",
    "print(dataset_sizes, flush=True) # OUTPUT: {'train': 5482, 'test': 1784}\n",
    "\n",
    "\n",
    "model = ResTCN().to(device)\n",
    "model.load_state_dict(torch.load(r\"resTCN_model_aug_weighted.pth\"))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "running_loss=0\n",
    "for phase in ['test']:\n",
    "        model.eval()\n",
    "        running_loss = .0\n",
    "        y_trues = np.empty([0])\n",
    "        y_preds = np.empty([0])\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().squeeze().to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            try:\n",
    "                preds = torch.max(softmax(outputs), dim=1)[1]  # Fix here\n",
    "                # print('HI')\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                continue\n",
    "            \n",
    "\n",
    "            y_trues = np.append(y_trues, labels.data.cpu().numpy())\n",
    "            y_preds = np.append(y_preds, preds.cpu())\n",
    "            \n",
    "            \n",
    "        # if phase == 'train':\n",
    "        #     scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        val_losses.append(epoch_loss)\n",
    "\n",
    "        print(\"[{}] Epoch: {}/{} Loss: {} LR: {}\".format(\n",
    "            phase, 0 + 1, num_epochs, epoch_loss, scheduler.get_last_lr()), flush=True)\n",
    "        print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))\n",
    "        print('\\naccuracy\\t' + str(accuracy_score(y_trues, y_preds)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n",
      "{'train': 5482, 'test': 1720}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/287 [00:00<?, ?it/s]c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "100%|██████████| 287/287 [03:27<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 1/25 Loss: 1.6277855031365571 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   1  19   3]\n",
      " [  0   0  93  67]\n",
      " [  0  15 466 431]\n",
      " [  0   9 217 399]]\n",
      "\n",
      "accuracy\t0.502906976744186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from ResTCN import ResTCN\n",
    "from utils import get_dataloader\n",
    "\n",
    "os.chdir(r\"F:\\RESTCN_CODE\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_epochs = 25\n",
    "batch_size = 6\n",
    "lr = .001\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "\n",
    "# dataloader = get_dataloader(batch_size,\n",
    "#                             'train.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_train'),\n",
    "#                             'test.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_test'))\n",
    "dataloader = get_dataloader(batch_size,\n",
    "                            'csv\\\\train.csv',\n",
    "                            os.getcwd(),\n",
    "                            'csv\\\\validation.csv',\n",
    "                            os.getcwd())\n",
    "\n",
    "dataset_sizes = {x: len(dataloader[x].dataset) for x in ['train','test']}\n",
    "print(dataset_sizes, flush=True) # OUTPUT: {'train': 5482, 'test': 1784}\n",
    "\n",
    "\n",
    "model = ResTCN().to(device)\n",
    "model.load_state_dict(torch.load(r\"resTCN_mod_model_weighted.pth\"))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "running_loss=0\n",
    "for phase in ['test']:\n",
    "        model.eval()\n",
    "        running_loss = .0\n",
    "        y_trues = np.empty([0])\n",
    "        y_preds = np.empty([0])\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().squeeze().to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            try:\n",
    "                preds = torch.max(softmax(outputs), dim=1)[1]  # Fix here\n",
    "                # print('HI')\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                continue\n",
    "            \n",
    "\n",
    "            y_trues = np.append(y_trues, labels.data.cpu().numpy())\n",
    "            y_preds = np.append(y_preds, preds.cpu())\n",
    "            \n",
    "            \n",
    "        # if phase == 'train':\n",
    "        #     scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        val_losses.append(epoch_loss)\n",
    "\n",
    "        print(\"[{}] Epoch: {}/{} Loss: {} LR: {}\".format(\n",
    "            phase, 0 + 1, num_epochs, epoch_loss, scheduler.get_last_lr()), flush=True)\n",
    "        print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))\n",
    "        print('\\naccuracy\\t' + str(accuracy_score(y_trues, y_preds)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n",
      "{'train': 5482, 'test': 1720}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 0/287 [00:00<?, ?it/s]c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manvendra Nema\\anaconda3\\envs\\vercil\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "100%|██████████| 287/287 [03:31<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Epoch: 1/25 Loss: 1.6461322551203328 LR: [0.001]\n",
      "\n",
      "confusion matrix\n",
      "[[  0   0  11  12]\n",
      " [  0   0  60 100]\n",
      " [  0   0 340 572]\n",
      " [  0   0 174 451]]\n",
      "\n",
      "accuracy\t0.45988372093023255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from ResTCN import ResTCN\n",
    "from utils import get_dataloader\n",
    "\n",
    "os.chdir(r\"F:\\RESTCN_CODE\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "num_epochs = 25\n",
    "batch_size = 6\n",
    "lr = .001\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device being used:\", device, flush=True)\n",
    "\n",
    "\n",
    "# dataloader = get_dataloader(batch_size,\n",
    "#                             'train.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_train'),\n",
    "#                             'test.csv',\n",
    "#                             os.path.join(os.getcwd(), 'images_test'))\n",
    "dataloader = get_dataloader(batch_size,\n",
    "                            'csv\\\\train.csv',\n",
    "                            os.getcwd(),\n",
    "                            'csv\\\\validation.csv',\n",
    "                            os.getcwd())\n",
    "\n",
    "dataset_sizes = {x: len(dataloader[x].dataset) for x in ['train','test']}\n",
    "print(dataset_sizes, flush=True) # OUTPUT: {'train': 5482, 'test': 1784}\n",
    "\n",
    "\n",
    "model = ResTCN().to(device)\n",
    "model.load_state_dict(torch.load(r\"resTCN_mod_model_weighted-1.pth\"))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "running_loss=0\n",
    "for phase in ['test']:\n",
    "        model.eval()\n",
    "        running_loss = .0\n",
    "        y_trues = np.empty([0])\n",
    "        y_preds = np.empty([0])\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.long().squeeze().to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            try:\n",
    "                preds = torch.max(softmax(outputs), dim=1)[1]  # Fix here\n",
    "                # print('HI')\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                continue\n",
    "            \n",
    "\n",
    "            y_trues = np.append(y_trues, labels.data.cpu().numpy())\n",
    "            y_preds = np.append(y_preds, preds.cpu())\n",
    "            \n",
    "            \n",
    "        # if phase == 'train':\n",
    "        #     scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        val_losses.append(epoch_loss)\n",
    "\n",
    "        print(\"[{}] Epoch: {}/{} Loss: {} LR: {}\".format(\n",
    "            phase, 0 + 1, num_epochs, epoch_loss, scheduler.get_last_lr()), flush=True)\n",
    "        print('\\nconfusion matrix\\n' + str(confusion_matrix(y_trues, y_preds)))\n",
    "        print('\\naccuracy\\t' + str(accuracy_score(y_trues, y_preds)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vercil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
